{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIPeZFc8WUocIPVsN2KaaJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dayody/RAG_System_QA/blob/main/RAGQA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Retrieval-Augmented Generation (RAG) System for AI Research Papers (Google Colab)\n",
        "This notebook implements a RAG system to answer questions based on a collection of AI research papers, adapted to run in Google Colab.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kbnoLWX5AZUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 1: Install Required Libraries\n",
        "# ------------------------------------\n",
        "# We use '!' to run shell commands in Colab. This installs all necessary packages.\n",
        "\n",
        "!pip install -q langchain langchain-openai langchain-community pypdf faiss-cpu tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3EzvJoI-W7c",
        "outputId": "7f7b8a58-9fd4-4d55-debc-59e546b7dbdb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/70.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/2.5 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.7/309.7 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 2: Import Libraries and Set OpenAI API Key\n",
        "# ---------------------------------------------------------\n",
        "# This cell imports all necessary packages and securely prompts you to enter your\n",
        "# OpenAI API key.\n",
        "\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "# Core LangChain and community module imports\n",
        "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain.schema import Document\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.runnable import RunnablePassthrough, RunnableParallel\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "\n",
        "# Securely get the OpenAI API key from the user\n",
        "if 'OPENAI_API_KEY' not in os.environ:\n",
        "    os.environ['OPENAI_API_KEY'] = getpass.getpass('Enter your OpenAI API key: ')\n",
        "\n",
        "if \"OPENAI_API_KEY\" in os.environ:\n",
        "    print(\"\\nOpenAI API key set successfully.\")\n",
        "else:\n",
        "    print(\"\\nError: OpenAI API key was not set.\")\n",
        "\n",
        "\n",
        "# %%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKl-NbqT-jLM",
        "outputId": "86913f38-a7fa-4e00-8cf9-eae0456797fb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your OpenAI API key: ··········\n",
            "\n",
            "OpenAI API key set successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 3: Upload PDF Files\n",
        "# --------------------------\n",
        "# This cell allows you to upload your research papers to the Colab environment.\n",
        "# It will create a 'papers' directory to store them.\n",
        "\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Please upload your PDF research papers.\")\n",
        "# Create a directory to store the papers\n",
        "papers_dir = 'papers'\n",
        "if os.path.exists(papers_dir):\n",
        "    shutil.rmtree(papers_dir) # Clean up previous uploads\n",
        "os.makedirs(papers_dir)\n",
        "\n",
        "# Upload files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Move uploaded files to the 'papers' directory\n",
        "for filename in uploaded.keys():\n",
        "    shutil.move(filename, os.path.join(papers_dir, filename))\n",
        "\n",
        "print(f\"\\nUploaded {len(uploaded)} files to the '{papers_dir}' directory.\")\n",
        "\n",
        "\n",
        "# %%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "av1XnDiu-vgz",
        "outputId": "2597240a-7358-4f57-b5fc-7242d7eb5153"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your PDF research papers.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-91c845ce-fbd6-4567-885d-31bd01b6de3d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-91c845ce-fbd6-4567-885d-31bd01b6de3d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 1706.03762v7.pdf to 1706.03762v7.pdf\n",
            "Saving 2005.11401v4.pdf to 2005.11401v4.pdf\n",
            "Saving 2005.14165v4.pdf to 2005.14165v4.pdf\n",
            "\n",
            "Uploaded 3 files to the 'papers' directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 4: Deliverable 1 - Document Preprocessing\n",
        "# ------------------------------------------------\n",
        "# We load the PDF documents from the 'papers/' directory and then split them\n",
        "# into smaller, overlapping chunks.\n",
        "\n",
        "print(\"\\nLoading and preprocessing documents...\")\n",
        "\n",
        "try:\n",
        "    loader = PyPDFDirectoryLoader(\"papers/\")\n",
        "    docs_before_split = loader.load()\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=150,\n",
        "        length_function=len,\n",
        "        is_separator_regex=False,\n",
        "    )\n",
        "    docs_chunked = text_splitter.split_documents(docs_before_split)\n",
        "\n",
        "    print(f\"Successfully loaded {len(docs_before_split)} documents.\")\n",
        "    print(f\"Split documents into {len(docs_chunked)} chunks.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "    print(\"Please ensure you have uploaded valid PDF files in the previous step.\")\n",
        "\n",
        "\n",
        "# %%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DLXkf-r_AGx",
        "outputId": "dab5c73e-1bb6-4cb5-ab91-fd99e57c7cbb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading and preprocessing documents...\n",
            "Successfully loaded 109 documents.\n",
            "Split documents into 450 chunks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 5: Deliverable 2 - Building the Retrieval System\n",
        "# -------------------------------------------------------\n",
        "# This cell converts the text chunks into numerical vectors (embeddings) and\n",
        "# stores them in a FAISS vector store for efficient searching.\n",
        "\n",
        "print(\"\\nCreating vector store and retriever...\")\n",
        "\n",
        "try:\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    vectorstore = FAISS.from_documents(docs_chunked, embeddings)\n",
        "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
        "    print(\"Vector store and retriever created successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during vector store creation: {e}\")\n",
        "\n",
        "\n",
        "# %%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvIhmBLR_FyD",
        "outputId": "74e88f52-9d29-4f1b-f6fd-3e4851ca869f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating vector store and retriever...\n",
            "Vector store and retriever created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 6: Deliverable 3 & 4 - Answer Generation and Source Attribution (Corrected)\n",
        "# ----------------------------------------------------------------------\n",
        "# Here, we define the complete RAG chain using a robust pattern that\n",
        "# prevents the data type error. The retriever is called once, and its\n",
        "# output (the Document objects) is correctly passed for both answer\n",
        "# generation and source attribution.\n",
        "\n",
        "print(\"\\nDefining the RAG chain...\")\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "You are an expert assistant for question-answering tasks.\n",
        "Use the following retrieved context to answer the question.\n",
        "If you don't know the answer from the context, just say that you don't know.\n",
        "Keep the answer concise and use a maximum of three sentences.\n",
        "\n",
        "CONTEXT:\n",
        "{context}\n",
        "\n",
        "QUESTION:\n",
        "{question}\n",
        "\n",
        "ANSWER:\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "# This is the corrected chain.\n",
        "# It ensures the retriever is called with the question string and\n",
        "# the context is properly formatted and passed to the prompt.\n",
        "rag_chain_with_sources = RunnableParallel(\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        ").assign(\n",
        "    answer=(\n",
        "        RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
        "        | prompt\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        ")\n",
        "\n",
        "print(\"RAG chain with source attribution is ready.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr2_EBcT_QZa",
        "outputId": "c8203c41-1fae-4c5c-fe78-7fa330ca25c6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Defining the RAG chain...\n",
            "RAG chain with source attribution is ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 7: Testing the RAG System\n",
        "# --------------------------------\n",
        "# This cell provides a function to query the RAG system and then runs the\n",
        "# sample questions provided in the project description.\n",
        "\n",
        "def ask_question(query: str):\n",
        "    \"\"\"\n",
        "    Invokes the RAG chain with a query and prints the answer and its sources.\n",
        "    \"\"\"\n",
        "    if 'rag_chain_with_sources' not in globals():\n",
        "        print(\"RAG chain is not defined. Please run the previous cells.\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\n{'='*20}\\nQuery: {query}\\n{'='*20}\")\n",
        "\n",
        "    try:\n",
        "        response = rag_chain_with_sources.invoke(query)\n",
        "        answer = response[\"answer\"]\n",
        "        sources = response[\"context\"]\n",
        "\n",
        "        print(\"ANSWER:\")\n",
        "        print(answer)\n",
        "\n",
        "        print(\"\\nSOURCES:\")\n",
        "        if sources:\n",
        "            for i, source_doc in enumerate(sources):\n",
        "                source_name = os.path.basename(source_doc.metadata.get('source', 'Unknown'))\n",
        "                page_number = source_doc.metadata.get('page', 'N/A')\n",
        "                print(f\"  - Source {i+1}: {source_name}, Page: {page_number}\")\n",
        "        else:\n",
        "            print(\"  - No sources were retrieved for this answer.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while processing the query: {e}\")\n",
        "\n",
        "\n",
        "# List of sample questions to test the system\n",
        "sample_questions = [\n",
        "    \"What are the main components of a RAG model, and how do they interact?\",\n",
        "    \"What are the two sub-layers in each encoder layer of the Transformer model?\",\n",
        "    \"Explain how positional encoding is implemented in Transformers and why it is necessary.\",\n",
        "    \"Describe the concept of multi-head attention in the Transformer architecture. Why is it beneficial?\",\n",
        "    \"What is few-shot learning, and how does GPT-3 implement it during inference?\"\n",
        "]\n",
        "\n",
        "# Iterate through the questions and get answers\n",
        "for q in sample_questions:\n",
        "    ask_question(q)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SzrSRd5_W93",
        "outputId": "8effe446-d17d-4284-8aaa-83f411eadad7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================\n",
            "Query: What are the main components of a RAG model, and how do they interact?\n",
            "====================\n",
            "ANSWER:\n",
            "The main components of a RAG model are a retrieval component and a generation component. They interact by retrieving relevant information from a large corpus of documents and using that information to generate specific and factual answers.\n",
            "\n",
            "SOURCES:\n",
            "  - Source 1: 2005.11401v4.pdf, Page: 8\n",
            "  - Source 2: 2005.11401v4.pdf, Page: 4\n",
            "  - Source 3: 2005.11401v4.pdf, Page: 8\n",
            "  - Source 4: 2005.11401v4.pdf, Page: 1\n",
            "\n",
            "====================\n",
            "Query: What are the two sub-layers in each encoder layer of the Transformer model?\n",
            "====================\n",
            "ANSWER:\n",
            "The two sub-layers in each encoder layer of the Transformer model are a multi-head self-attention mechanism and a simple, position-wise fully connected feed-forward network.\n",
            "\n",
            "SOURCES:\n",
            "  - Source 1: 1706.03762v7.pdf, Page: 2\n",
            "  - Source 2: 1706.03762v7.pdf, Page: 1\n",
            "  - Source 3: 1706.03762v7.pdf, Page: 1\n",
            "  - Source 4: 1706.03762v7.pdf, Page: 4\n",
            "\n",
            "====================\n",
            "Query: Explain how positional encoding is implemented in Transformers and why it is necessary.\n",
            "====================\n",
            "ANSWER:\n",
            "Positional encoding in Transformers is implemented using sine and cosine functions of different frequencies, where each dimension corresponds to a sinusoid. This is necessary to allow the model to easily learn to attend by relative positions, as it provides information about the position of tokens in the sequence.\n",
            "\n",
            "SOURCES:\n",
            "  - Source 1: 1706.03762v7.pdf, Page: 5\n",
            "  - Source 2: 1706.03762v7.pdf, Page: 8\n",
            "  - Source 3: 1706.03762v7.pdf, Page: 1\n",
            "  - Source 4: 1706.03762v7.pdf, Page: 4\n",
            "\n",
            "====================\n",
            "Query: Describe the concept of multi-head attention in the Transformer architecture. Why is it beneficial?\n",
            "====================\n",
            "ANSWER:\n",
            "Multi-head attention in the Transformer architecture allows the model to attend to different information from various representation subspaces simultaneously. By using multiple attention heads, the model can capture complex dependencies and patterns in the input data more effectively, leading to improved performance in tasks such as sequence modeling and transduction.\n",
            "\n",
            "SOURCES:\n",
            "  - Source 1: 1706.03762v7.pdf, Page: 4\n",
            "  - Source 2: 1706.03762v7.pdf, Page: 1\n",
            "  - Source 3: 1706.03762v7.pdf, Page: 1\n",
            "  - Source 4: 1706.03762v7.pdf, Page: 1\n",
            "\n",
            "====================\n",
            "Query: What is few-shot learning, and how does GPT-3 implement it during inference?\n",
            "====================\n",
            "ANSWER:\n",
            "Few-shot learning involves learning new tasks with only a few examples. GPT-3 implements few-shot learning during inference by recognizing and identifying tasks it has learned during training, adapting to specific styles of tasks, and potentially learning entirely new skills.\n",
            "\n",
            "SOURCES:\n",
            "  - Source 1: 2005.14165v4.pdf, Page: 4\n",
            "  - Source 2: 2005.14165v4.pdf, Page: 33\n",
            "  - Source 3: 2005.14165v4.pdf, Page: 28\n",
            "  - Source 4: 2005.14165v4.pdf, Page: 4\n"
          ]
        }
      ]
    }
  ]
}